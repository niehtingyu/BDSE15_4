{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import databricks.koalas as ks\n",
    "import math\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = os.listdir(\"./mini_open_sky\")\n",
    "csvYearly = [i for i in fileList if i.startswith(\"mini_flightlist_2019\")]\n",
    "csvYearly.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfList = [ks.read_csv(\"/user/hadoop/mini_open_sky/\" + i) for i in csvYearly]\n",
    "# dfList = [ks.read_csv(\"file:///home/hadoop/mini_open_sky/\" + i) for i in csvYearly]\n",
    "dfList = [ks.read_csv(\"./mini_open_sky/\" + i) for i in csvYearly]\n",
    "openSkyDf = ks.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icaoDf = ks.read_csv(\"/user/hadoop/mini_icao/mini_ICAO.csv\")\n",
    "# icaoDf = ks.read_csv(\"file:///home/hadoop/mini_icao/mini_ICAO.csv\")\n",
    "icaoDf = ks.read_csv(\"./mini_icao/mini_ICAO.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDf = ks.DataFrame(icaoDf[\"icao_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domestic and International"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "df2 = openSkyDf.dropna(subset = [\"origin\", \"destination\"], how = \"any\")\n",
    "\n",
    "# select column from icao data\n",
    "df3_1 = icaoDf[[\"ident\", \"iso_country\"]]\n",
    "\n",
    "# use 'origin' field to map the combined opensky dataset and icao table to get airport country\n",
    "df3_2 = ks.merge(df2, df3_1, left_on = \"origin\", right_on = \"ident\", how = \"left\") \\\n",
    "          .drop([\"ident\"], axis = 1) \\\n",
    "          .rename(columns={\"iso_country\": \"origin_iso_country\"})\n",
    "\n",
    "# use 'destination' field to map the combined opensky dataset and icao table to get airport country\n",
    "df3_2 = ks.merge(df3_2, df3_1, left_on = \"destination\", right_on = \"ident\", how = \"left\") \\\n",
    "          .drop([\"ident\"], axis = 1) \\\n",
    "          .rename(columns={\"iso_country\": \"destination_iso_country\"})\n",
    "\n",
    "# create a field to determine whether it is a domestic line\n",
    "df3_2[\"domestic\"] = df3_2[\"origin_iso_country\"] == df3_2[\"destination_iso_country\"]\n",
    "\n",
    "# count domestic_origin\n",
    "df3_3 = df3_2[df3_2[\"domestic\"] == True].groupby(\"origin\").count()\n",
    "se3_3 = df3_3.iloc[:, -1]\n",
    "se3_3.name = \"domestic_origin\"\n",
    "\n",
    "# count domestic_destination\n",
    "df3_4 = df3_2[df3_2[\"domestic\"] == True].groupby(\"destination\").count()\n",
    "se3_4 = df3_4.iloc[:, -1]\n",
    "se3_4.name = \"domestic_destination\"\n",
    "\n",
    "# count international_origin\n",
    "df3_5 = df3_2[df3_2[\"domestic\"] == False].groupby(\"origin\").count()\n",
    "se3_5 = df3_5.iloc[:, -1]\n",
    "se3_5.name = \"international_origin\"\n",
    "\n",
    "# count international_destination\n",
    "df3_6 = df3_2[df3_2[\"domestic\"] == False].groupby(\"destination\").count()\n",
    "se3_6 = df3_6.iloc[:, -1]\n",
    "se3_6.name = \"international_destination\"\n",
    "\n",
    "# icao merge domestic_origin\n",
    "df4 = ks.merge(df3_1, se3_3, left_on = \"ident\", right_index = True, how = \"outer\")\n",
    "df4[\"domestic_origin\"] = df4[\"domestic_origin\"].fillna(0)\n",
    "\n",
    "# icao merge domestic_destination\n",
    "df4 = ks.merge(df4, se3_4, left_on = \"ident\", right_index = True, how = \"outer\")\n",
    "df4[\"domestic_destination\"] = df4[\"domestic_destination\"].fillna(0)\n",
    "\n",
    "# icao merge international_origin\n",
    "df4 = ks.merge(df4, se3_5, left_on = \"ident\", right_index = True, how = \"outer\")\n",
    "df4[\"international_origin\"] = df4[\"international_origin\"].fillna(0)\n",
    "\n",
    "# icao merge international_destination\n",
    "df4 = ks.merge(df4, se3_6, left_on = \"ident\", right_index = True, how = \"outer\")\n",
    "df4[\"international_destination\"] = df4[\"international_destination\"].fillna(0)\n",
    "\n",
    "# prepare to output\n",
    "df5 = df4.rename(columns = {\"ident\": \"icao_code\"}).drop(\"iso_country\", axis = 1)\n",
    "\n",
    "# integrate to output dataframe\n",
    "outputDf = ks.merge(outputDf, df5, left_on = \"icao_code\", right_on = \"icao_code\", how = \"left\")\n",
    "\n",
    "# delete temporary objects\n",
    "del df2, df3_1, df3_2, df3_3, se3_3, df3_4, se3_4, df3_5, se3_5, df3_6, se3_6, df4, df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day and Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/functions.py:383: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-180   <= zone 13 (return -12) < -172.5 | 18 -  5 day |  6 - 17 night\n",
    "-172.5 <= zone 24 (return -11) < -157.5 | 17 -  4 day |  5 - 16 night\n",
    "-157.5 <= zone 23 (return -10) < -142.5 | 16 -  3 day |  4 - 15 night\n",
    "-142.5 <= zone 22 (return  -9) < -127.5 | 15 -  2 day |  3 - 14 night\n",
    "-127.5 <= zone 21 (return  -8) < -112.5 | 14 -  1 day |  2 - 13 night\n",
    "-112.5 <= zone 20 (return  -7) <  -97.5 | 13 -  0 day |  1 - 12 night\n",
    " -97.5 <= zone 19 (return  -6) <  -82.5 | 12 - 23 day |  0 - 11 night\n",
    " -82.5 <= zone 18 (return  -5) <  -67.5 | 11 - 22 day | 23 - 10 night\n",
    " -67.5 <= zone 17 (return  -4) <  -52.5 | 10 - 21 day | 22 -  9 night\n",
    " -52.5 <= zone 16 (return  -3) <  -37.5 |  9 - 20 day | 21 -  8 night\n",
    " -37.5 <= zone 15 (return  -2) <  -22.5 |  8 - 19 day | 20 -  7 night\n",
    " -22.5 <= zone 14 (return  -1) <   -7.5 |  7 - 18 day | 19 -  6 night\n",
    "  -7.5 <= zone  1 (return   0) <    7.5 |  6 - 17 day | 18 -  5 night\n",
    "   7.5 <= zone  2 (return   1) <   22.5 |  5 - 16 day | 17 -  4 night\n",
    "  22.5 <= zone  3 (return   2) <   37.5 |  4 - 15 day | 16 -  3 night\n",
    "  37.5 <= zone  4 (return   3) <   52.5 |  3 - 14 day | 15 -  2 night\n",
    "  52.5 <= zone  5 (return   4) <   67.5 |  2 - 13 day | 14 -  1 night\n",
    "  67.5 <= zone  6 (return   5) <   82.5 |  1 - 12 day | 13 -  0 night\n",
    "  82.5 <= zone  7 (return   6) <   97.5 |  0 - 11 day | 12 - 23 night\n",
    "  97.5 <= zone  8 (return   7) <  112.5 | 23 - 10 day | 11 - 22 night\n",
    " 112.5 <= zone  9 (return   8) <  127.5 | 22 -  9 day | 10 - 21 night\n",
    " 127.5 <= zone 10 (return   9) <  142.5 | 21 -  8 day |  9 - 20 night\n",
    " 142.5 <= zone 11 (return  10) <  157.5 | 20 -  7 day |  8 - 19 night\n",
    " 157.5 <= zone 12 (return  11) <  172.5 | 19 -  6 day |  7 - 18 night\n",
    " 172.5 <= zone 13 (return  12) <  180   | 18 -  5 day |  6 - 17 night\n",
    "\"\"\"\n",
    "\n",
    "# prepare dataframe, dropna, rename, and convert to datetime\n",
    "ori_first = openSkyDf[[\"origin\", \"firstseen\"]].dropna(subset = [\"origin\", \"firstseen\"], how = \"any\")\n",
    "ori_first = ori_first.rename({\"origin\": \"ident\"}, axis = 1)\n",
    "ori_first[\"firstseen\"] = ks.to_datetime(ori_first[\"firstseen\"])\n",
    "\n",
    "des_last = openSkyDf[[\"destination\", \"lastseen\"]].dropna(subset = [\"destination\", \"lastseen\"], how = \"any\")\n",
    "des_last = des_last.rename({\"destination\": \"ident\"}, axis = 1)\n",
    "des_last[\"lastseen\"] = ks.to_datetime(des_last[\"lastseen\"])\n",
    "\n",
    "air = icaoDf[[\"ident\", \"longitude_deg\"]]\n",
    "\n",
    "# label different time zones\n",
    "ks.set_option(\"compute.ops_on_diff_frames\", True)\n",
    "\n",
    "def zone_classifier(row):\n",
    "    return math.floor((7.5 + row[\"longitude_deg\"]) / 15)\n",
    "\n",
    "air[\"zone_tag\"] = air.apply(lambda x: zone_classifier(x), axis = 1)\n",
    "\n",
    "# ready to count origin day and night\n",
    "ori_df = ks.merge(ori_first, air, on = \"ident\" ,how = \"left\")\n",
    "\n",
    "# label day, night of different time zones\n",
    "def ori_day_night_classifier(row):\n",
    "    if (-12 <= row[\"zone_tag\"]) and (row[\"zone_tag\"] <= -7):\n",
    "        if ((-6 - row[\"zone_tag\"]) <= row[\"firstseen\"].hour) and (row[\"firstseen\"].hour <= (5 - row[\"zone_tag\"])):\n",
    "            return \"night_origin\"\n",
    "        else:\n",
    "            return \"day_origin\"\n",
    "    elif (-6 <= row[\"zone_tag\"]) and (row[\"zone_tag\"] <= 6):\n",
    "        if ((6 - row[\"zone_tag\"]) <= row[\"firstseen\"].hour) and (row[\"firstseen\"].hour <= (17 - row[\"zone_tag\"])):\n",
    "            return \"day_origin\"\n",
    "        else:\n",
    "            return \"night_origin\"\n",
    "    elif (7 <= row[\"zone_tag\"]) and (row[\"zone_tag\"] <= 12):\n",
    "        if ((18 - row[\"zone_tag\"]) <= row[\"firstseen\"].hour) and (row[\"firstseen\"].hour <= (29 - row[\"zone_tag\"])):\n",
    "            return \"night_origin\"\n",
    "        else:\n",
    "            return \"day_origin\"\n",
    "\n",
    "ori_df[\"day_night_tag\"] = ori_df.apply(lambda x: ori_day_night_classifier(x), axis = 1)\n",
    "\n",
    "# count origin day and night\n",
    "firstseen_count = ori_df.groupby([\"ident\", \"day_night_tag\"])[\"ident\"].count().unstack()\n",
    "firstseen_count = firstseen_count.reset_index().rename(columns={\"ident\": \"icao_code\"})\n",
    "\n",
    "# ready to count destination day and night\n",
    "des_df = ks.merge(des_last, air, on = \"ident\" ,how = \"left\")\n",
    "\n",
    "# label day, night of different time zones\n",
    "def des_day_night_classifier(row):\n",
    "    if (-12 <= row[\"zone_tag\"]) and (row[\"zone_tag\"] <= -7):\n",
    "        if ((-6 - row[\"zone_tag\"]) <= row[\"lastseen\"].hour) and (row[\"lastseen\"].hour <= (5 - row[\"zone_tag\"])):\n",
    "            return \"night_destination\"\n",
    "        else:\n",
    "            return \"day_destination\"\n",
    "    elif (-6 <= row[\"zone_tag\"]) and (row[\"zone_tag\"] <= 6):\n",
    "        if ((6 - row[\"zone_tag\"]) <= row[\"lastseen\"].hour) and (row[\"lastseen\"].hour <= (17 - row[\"zone_tag\"])):\n",
    "            return \"day_destination\"\n",
    "        else:\n",
    "            return \"night_destination\"\n",
    "    elif (7 <= row[\"zone_tag\"]) and (row[\"zone_tag\"] <= 12):\n",
    "        if ((18 - row[\"zone_tag\"]) <= row[\"lastseen\"].hour) and (row[\"lastseen\"].hour <= (29 - row[\"zone_tag\"])):\n",
    "            return \"night_destination\"\n",
    "        else:\n",
    "            return \"day_destination\"\n",
    "\n",
    "des_df[\"day_night_tag\"] = des_df.apply(lambda x: des_day_night_classifier(x), axis = 1)\n",
    "\n",
    "# count destination day and night\n",
    "lastseen_count = des_df.groupby([\"ident\", \"day_night_tag\"])[\"ident\"].count().unstack()\n",
    "lastseen_count = lastseen_count.reset_index().rename(columns={\"ident\": \"icao_code\"})\n",
    "\n",
    "# prepare to output\n",
    "together = ks.DataFrame(icaoDf[\"icao_code\"])\n",
    "together = ks.merge(together, firstseen_count, on = \"icao_code\", how = \"left\")\n",
    "together = ks.merge(together, lastseen_count, on = \"icao_code\", how = \"left\").fillna(0)\n",
    "\n",
    "# integrate to output dataframe\n",
    "outputDf = ks.merge(outputDf, together, left_on = \"icao_code\", right_on = \"icao_code\", how = \"left\")\n",
    "\n",
    "# delete temporary objects\n",
    "del ori_first, des_last, air, ori_df, firstseen_count, des_df, lastseen_count, together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat year and month column\n",
    "df_combine = openSkyDf[[\"origin\", \"destination\", \"day\"]]\n",
    "df_combine[\"time\"] = ks.to_datetime(df_combine[\"day\"], format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "df_combine[\"year\"] = df_combine[\"time\"].dt.year\n",
    "df_combine[\"month\"] = df_combine[\"time\"].dt.month\n",
    "\n",
    "# prepare jan to dec column names\n",
    "mon_syntax = [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
    "mon_ind_ori = [i + \"_origin\" for i in mon_syntax]\n",
    "mon_ind_dest = [i + \"_destination\" for i in mon_syntax]\n",
    "\n",
    "# by month flights - origin\n",
    "ori_g = df_combine[[\"origin\", \"month\"]].dropna().groupby(\"origin\")[\"month\"].value_counts().unstack().fillna(0)\n",
    "# rename column name\n",
    "ori_g.columns = mon_ind_ori\n",
    "\n",
    "# by month flights - destination\n",
    "dest_g = df_combine[[\"destination\", \"month\"]].dropna().groupby(\"destination\")[\"month\"].value_counts().unstack().fillna(0)\n",
    "# rename column name\n",
    "dest_g.columns = mon_ind_dest\n",
    "\n",
    "# prepare to output\n",
    "ori_g_temp = ks.DataFrame(icaoDf[\"icao_code\"])\n",
    "ori_g_temp = ks.merge(ori_g_temp, ori_g, left_on = \"icao_code\", right_index = True, how = \"left\").fillna(0)\n",
    "dest_g_temp = ks.DataFrame(icaoDf[\"icao_code\"])\n",
    "dest_g_temp = ks.merge(dest_g_temp, dest_g, left_on = \"icao_code\", right_index = True, how = \"left\").fillna(0)\n",
    "\n",
    "# calculate min/max\n",
    "ks.set_option(\"compute.ops_on_diff_frames\", True)\n",
    "# origin\n",
    "ks_ori = ks.DataFrame(ori_g.apply(lambda x: min(x), axis = 1))\n",
    "ks_ori[\"max_month_flights_origin\"] = ori_g.apply(lambda x: max(x), axis = 1)\n",
    "ks_ori = ks_ori.reset_index().rename(columns = {0: \"min_month_flights_origin\"})\n",
    "# destination\n",
    "ks_dest = ks.DataFrame(dest_g.apply(lambda x: min(x), axis = 1))\n",
    "ks_dest[\"max_month_flights_destination\"] = dest_g.apply(lambda x: max(x), axis = 1)\n",
    "ks_dest = ks_dest.reset_index().rename(columns = {0: \"min_month_flights_destination\"})\n",
    "\n",
    "# integrate to output dataframe\n",
    "outputDf = ks.merge(outputDf, ori_g_temp, left_on = \"icao_code\", right_on = \"icao_code\", how = \"left\")\n",
    "outputDf = ks.merge(outputDf, dest_g_temp, left_on = \"icao_code\", right_on = \"icao_code\", how = \"left\")\n",
    "outputDf = ks.merge(outputDf, ks_ori, left_on = \"icao_code\", right_on = \"origin\", how = \"left\").drop([\"origin\"], axis = 1)\n",
    "outputDf = ks.merge(outputDf, ks_dest, left_on = \"icao_code\", right_on = \"destination\", how = \"left\").drop([\"destination\"], axis = 1)\n",
    "\n",
    "# delete temporary objects\n",
    "del df_combine, mon_syntax, mon_ind_ori, mon_ind_dest, ori_g, dest_g, ori_g_temp, dest_g_temp, ks_ori, ks_dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long, Medium and Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "df1 = openSkyDf.dropna(subset = [\"origin\", \"destination\"], how = \"any\")\n",
    "\n",
    "# merge latitude and longitude points table about origin and destination\n",
    "df2 = icaoDf[[\"ident\",\"latitude_deg\",\"longitude_deg\"]]\n",
    "\n",
    "df3 = ks.merge(df2, df1, left_on = \"ident\", right_on = \"origin\", how = \"left\") \\\n",
    "        .rename(columns = {\"latitude_deg\": \"airport_o_latitude\", \"longitude_deg\": \"airport_o_longitude\"})\n",
    "\n",
    "df4 = ks.merge(df2, df3, left_on = \"ident\", right_on = \"destination\", how = \"left\") \\\n",
    "        .rename(columns = {\"latitude_deg\": \"airport_d_latitude\", \"longitude_deg\": \"airport_d_longitude\"})\n",
    "\n",
    "# calculate the distance between two latitude and longitude points\n",
    "ks.set_option(\"compute.ops_on_diff_frames\", True)\n",
    "\n",
    "def cal_distance(row):\n",
    "    lat1 = row[\"airport_o_latitude\"]\n",
    "    long1 = row[\"airport_o_longitude\"]\n",
    "    lat2 = row[\"airport_d_latitude\"]\n",
    "    long2 = row[\"airport_d_longitude\"]\n",
    "    g1 = (lat1, long1)\n",
    "    g2 = (lat2, long2)\n",
    "    ret = haversine(g1, g2)\n",
    "    result = \"%.7f\" % ret\n",
    "    return result\n",
    "\n",
    "df4[\"distance\"] = df4.apply(lambda x: cal_distance(x), axis = 1)\n",
    "df4[\"distance\"] = df4[\"distance\"].astype(float)\n",
    "\n",
    "# df4[\"distance_group\"] = pd.cut(df2[\"distance\"], bins = [0, 1300, 4450, 1.979048e+07], labels = [\"short\", \"medium\", \"long\"])\n",
    "def categorizer(row):\n",
    "    if row[\"distance\"] < 1300:\n",
    "        return \"short\"\n",
    "    elif row[\"distance\"] < 4450:\n",
    "        return \"medium\"\n",
    "    elif row[\"distance\"] >= 4450:\n",
    "        return \"long\"\n",
    "\n",
    "df4[\"distance_group\"] = df4.apply(categorizer, axis = 1)\n",
    "\n",
    "# group origin with categories\n",
    "df5 = df4.groupby([\"origin\", \"distance_group\"])[\"origin\"].count().unstack()\n",
    "df5 = df5.rename(columns = {\"short\": \"short_origin\", \"medium\": \"medium_origin\", \"long\": \"long_origin\"})\n",
    "\n",
    "# group destination with categories\n",
    "df6 = df4.groupby([\"destination\", \"distance_group\"])[\"destination\"].count().unstack()\n",
    "df6 = df6.rename(columns = {\"short\": \"short_destination\", \"medium\": \"medium_destination\", \"long\": \"long_destination\"})\n",
    "\n",
    "# prepare to output\n",
    "df7 = ks.DataFrame(icaoDf[\"icao_code\"])\n",
    "df7 = ks.merge(df7, df5, left_on = \"icao_code\", right_index = True, how = \"left\")\n",
    "df7 = ks.merge(df7, df6, left_on = \"icao_code\", right_index = True, how = \"left\").fillna(0)\n",
    "\n",
    "# integrate to output dataframe\n",
    "outputDf = ks.merge(outputDf, df7, left_on = \"icao_code\", right_on = \"icao_code\", how = \"left\")\n",
    "\n",
    "# delete temporary objects\n",
    "del df1, df2, df3, df4, df5, df6, df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputDf.to_csv(\"/user/hadoop/mini_2019_airport_table\", index = False)\n",
    "# outputDf.to_csv(\"file:///home/hadoop/mini_2019_airport_table\", index = False)\n",
    "outputDf.to_csv(\"./mini_2019_airport_table\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
