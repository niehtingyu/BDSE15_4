{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import databricks.koalas as ks\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = os.listdir(\"./GlobalSurface/2019\")\n",
    "csvYearly = [i for i in fileList[:50]]\n",
    "csvYearly.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfList = [ks.read_csv(\"/user/hadoop/GlobalSurface/2019/\" + i) for i in csvYearly]\n",
    "# dfList = [ks.read_csv(\"file:///home/hadoop/GlobalSurface/2019/\" + i) for i in csvYearly]\n",
    "dfList = [ks.read_csv(\"./GlobalSurface/2019/\" + i) for i in csvYearly]\n",
    "globalSurfaceDf = ks.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icaoDf = ks.read_csv(\"/user/hadoop/mini_icao/mini_ICAO.csv\")\n",
    "# icaoDf = ks.read_csv(\"file:///home/hadoop/mini_icao/mini_ICAO.csv\")\n",
    "icaoDf = ks.read_csv(\"./mini_icao/mini_ICAO.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDf = ks.DataFrame(icaoDf[\"icao_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance between Airport and Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve needed features from icao data\n",
    "df1 = icaoDf.loc[:, [\"ident\", \"latitude_deg\", \"longitude_deg\", \"elevation_ft\"]]\n",
    "# elevation feet to m\n",
    "df1[\"elevation_ft\"] = df1[\"elevation_ft\"] * 0.3048\n",
    "df1 = df1.rename(columns = {\"elevation_ft\": \"elevation_m\"})\n",
    "\n",
    "# retrieve needed features from station data\n",
    "# dropna\n",
    "df2 = globalSurfaceDf.dropna(axis = 0)\n",
    "df2 = df2.loc[:, [\"STATION\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\"]].drop_duplicates()\n",
    "# change data type\n",
    "df2[\"LATITUDE\"] = df2[\"LATITUDE\"].astype(float)\n",
    "df2[\"LONGITUDE\"] = df2[\"LONGITUDE\"].astype(float)\n",
    "df2[\"ELEVATION\"] = df2[\"ELEVATION\"].astype(float)\n",
    "\n",
    "# cartesian combine icao data and station data\n",
    "df3 = df1.assign(key = 1).merge(df2.assign(key = 1), on = \"key\").drop(\"key\", axis = 1)\n",
    "\n",
    "# calculate the distance between two latitude and longitude points\n",
    "def distance(row):\n",
    "    lat1 = row[\"latitude_deg\"]\n",
    "    long1 = row[\"longitude_deg\"]\n",
    "    airport = (lat1, long1)\n",
    "    \n",
    "    lat2 = row[\"LATITUDE\"]\n",
    "    long2 = row[\"LONGITUDE\"]\n",
    "    station = (lat2, long2)\n",
    "    \n",
    "    result = haversine(airport, station)\n",
    "    return result\n",
    "\n",
    "# calculate distance by using haversine\n",
    "ks.set_option(\"compute.ops_on_diff_frames\", True)\n",
    "df3[\"airport_station_distance\"] = df3.apply(lambda x: distance(x), axis = 1)\n",
    "\n",
    "# take the minimum distance\n",
    "df4 = df3.iloc[df3.groupby(\"ident\")[\"airport_station_distance\"].idxmin().tolist(), :]\n",
    "\n",
    "# prepare to output\n",
    "df4 = df4.rename(columns={\"ident\": \"icao_code\"})\n",
    "\n",
    "# integrate to output dataframe\n",
    "outputDf = ks.merge(outputDf, df4, left_on = \"icao_code\", right_on = \"icao_code\", how = \"left\")\n",
    "\n",
    "# delete temporary objects\n",
    "del df1, df2, df3, df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropna\n",
    "df = globalSurfaceDf.dropna(axis = 0)\n",
    "\n",
    "# calculate features average\n",
    "df_temp = df.loc[df[\"TEMP\"] != 9999.9]\n",
    "df_temp = df_temp.groupby([\"STATION\"]).mean()\n",
    "\n",
    "df_vis = df.loc[df[\"VISIB\"] != 999.9]\n",
    "df_vis = df_vis.groupby([\"STATION\"]).mean()\n",
    "\n",
    "df_wd = df.loc[df[\"WDSP\"] != 999.9]\n",
    "df_wd = df_wd.groupby([\"STATION\"]).mean()\n",
    "\n",
    "df_max = df.loc[df[\"MAX\"] != 9999.9]\n",
    "df_max = df_max.groupby([\"STATION\"]).mean()\n",
    "\n",
    "df_min = df.loc[df[\"MIN\"] != 9999.9]\n",
    "df_min = df_min.groupby([\"STATION\"]).mean()\n",
    "\n",
    "df_prcp = df.loc[df[\"PRCP\"] != 99.99]\n",
    "df_prcp = df_prcp.groupby([\"STATION\"]).mean()\n",
    "\n",
    "# average temperature (Farenheit to Celsius)\n",
    "AVG_TEMP = 5 / 9 * (df_temp[\"TEMP\"] - 32)\n",
    "AVG_TEMP = AVG_TEMP.rename(\"AVG_TEMP\")\n",
    "\n",
    "# average visibility (mile to km)\n",
    "AVG_VISIB = df_vis[\"VISIB\"] * 1.61\n",
    "AVG_VISIB = AVG_VISIB.rename(\"AVG_VISIB\")\n",
    "\n",
    "# average wind speed (knot)\n",
    "AVG_WDSP = df_wd[\"WDSP\"]\n",
    "AVG_WDSP = AVG_WDSP.rename(\"AVG_WDSP\")\n",
    "\n",
    "# average maximum temperature (Farenheit to Celsius)\n",
    "AVG_MAX = 5 / 9 * (df_max[\"MAX\"] - 32)\n",
    "AVG_MAX = AVG_MAX.rename(\"AVG_MAX\")\n",
    "\n",
    "# average minimum temperature (Farenheit to Celsius)\n",
    "AVG_MIN = 5 / 9 * (df_min[\"MIN\"] - 32)\n",
    "AVG_MIN = AVG_MIN.rename(\"AVG_MIN\")\n",
    "\n",
    "# average precipitation (inch to mm)\n",
    "AVG_PRCP = df_prcp[\"PRCP\"] * 25.4\n",
    "AVG_PRCP = AVG_PRCP.rename(\"AVG_PRCP\")\n",
    "\n",
    "# combine columns needed to new dataframe\n",
    "ks.set_option(\"compute.ops_on_diff_frames\", True)\n",
    "df_concat = ks.concat([AVG_TEMP, AVG_VISIB, AVG_WDSP, AVG_MAX, AVG_MIN, AVG_PRCP], axis = 1)\n",
    "\n",
    "# integrate to output dataframe\n",
    "outputDf = ks.merge(outputDf, df_concat, left_on = \"STATION\", right_index = True, how = \"left\")\n",
    "\n",
    "# delete temporary objects\n",
    "del df, df_temp, df_vis, df_wd, df_max, df_min, df_prcp, AVG_TEMP, AVG_VISIB, AVG_WDSP, AVG_MAX, AVG_MIN, AVG_PRCP, df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputDf.to_csv(\"/user/hadoop/mini_2019_station_table\", index = False)\n",
    "# outputDf.to_csv(\"file:///home/hadoop/mini_2019_station_table\", index = False)\n",
    "outputDf.to_csv(\"./mini_2019_station_table\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
